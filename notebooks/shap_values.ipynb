{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOvszO1GfLENTAKT9nSbRiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stepsbtw/Machine-Learning/blob/main/notebooks/shap_values.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SHAP Values (SHapley Additive exPlanations)\n",
        "É um método para explicar as saídas de um modelo de aprendizado de máquina.\n",
        "\n",
        "Baseado nos **Shapley Values** da teoria dos jogos cooperativa.\n",
        "\n",
        "- Distribuir a predição do modelo (\"payout\") de maneira justa pelas features (\"players\")\n",
        "\n",
        "Calcular a **contribuição marginal** ao longo de todas as combinações de features possíveis (\"coalitions\")"
      ],
      "metadata": {
        "id": "FrciNiHlkgF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Passo a Passo\n",
        "1. Escolher um **background dataset** $D ⊆ ℝ^n$ (uma sample dos dados de treino).\n",
        "2. Modelo $h(x) : ℝ^n→ℝ$ e uma instancia $x ∈ ℝ^n$ para explicar.\n",
        "3. Computar o valor **SHAP baseline** (referencia) $\\phi_0$.\n",
        "4. Para cada feature, computar a **média ponderada das contribuições marginais** $\\phi_i$."
      ],
      "metadata": {
        "id": "THpTf5QPln8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Escolher um Background Dataset\n",
        "\n",
        "Selecione o dataset $D$ que representa a distribuição das features.\n",
        "- Esse dataset vai ser usada para simular o que o modelo iria predizer se algumas features estivessem \"Faltando\"\n",
        "- Tipicamente é um subconjunto dos dados de treino.\n",
        "- Notação: $D = \\{x^{(1)}, x^{(2)}, ⋯, x^{(m)}\\}$\n",
        "\n",
        "### 2) Modelo e Instância\n",
        "\n",
        "- Seja $h : ℝ^n → ℝ$ a **função preditora** (hipótese)\n",
        "- Seja $x = (x_1, x_2, ⋯, x_n)$ a instância que a saída $h(x)$ queremos explicar.\n",
        "\n",
        "### 3) Valor SHAP Baseline $\\phi_0$\n",
        "\n",
        "$$\n",
        "\\phi_0 = \\mathbb{E}_{x'∼D}[h(x')]\n",
        "$$\n",
        "\n",
        "$\\phi_0$ é o valor esperado que o modelo daria de saída em um background dataset $D$.\n",
        "\n",
        "- Representa a predição do modelo quando **não se conhece nenhuma feature**.\n",
        "- Todos os valores SHAP são computados relativos a este baseline.\n",
        "\n",
        "Um modelo não pode realmente produzir uma predição sem features.\n",
        "\n",
        "- Mas o SHAP aproxima qual seria a saída do modelo nessa situação, computando a predição esperada no background dataset.\n",
        "\n",
        "**O que o $x'$ significa ?**\n",
        "\n",
        "- $x'$ é uma única instância (uma linha) de $D$\n",
        "- $D$ é tipicamente um subconjunto de treino e é usado para simular o que o modelo prediz sem features.\n",
        "- A notação $\\mathbb{E}_{x'∼D}$ significa a predição média sobre todos os $x' \\in D$\n",
        "\n",
        "Portanto, na prática:\n",
        "\n",
        "$$\n",
        "\\phi_0 = \\frac{1}{|D|}∑_{x'∈D}h(x')\n",
        "$$\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "$$\n",
        "D = {(0,0), (0,1), (1,0), (1,1)}\n",
        "\\\\\\phi_0 = \\frac{1}{4}[h(0,0) + h(0,1) + h(1,0) + h(1,1)]\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "9OIylZxuN7uL"
      }
    }
  ]
}